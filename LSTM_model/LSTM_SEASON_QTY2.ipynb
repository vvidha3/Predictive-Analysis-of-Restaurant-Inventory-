{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from kerastuner.tuners import RandomSearch  # Adjusted import statement\n",
    "\n",
    "# Load the dataset from both sheets\n",
    "file_path = 'sam9.xlsx'  \n",
    "df_sheet1 = pd.read_excel(file_path, sheet_name='Sheet_1')\n",
    "df_sheet2 = pd.read_excel(file_path, sheet_name='Sheet_2')\n",
    "\n",
    "# Concatenate the dataframes\n",
    "df = pd.concat([df_sheet1, df_sheet2], ignore_index=True)\n",
    "\n",
    "# Preprocess the data\n",
    "df['datetime'] = pd.to_datetime(df['order_date'].astype(str) + ' ' + df['order_time'].astype(str))\n",
    "df['quantity'] = pd.to_numeric(df['quantity'], errors='coerce')\n",
    "\n",
    "# Aggregate the data by date to get the total quantity ordered each day\n",
    "daily_data = df.groupby(pd.Grouper(key='datetime', freq='D')).agg({'quantity': 'sum'}).reset_index()\n",
    "\n",
    "# Add seasonality features\n",
    "daily_data['day_of_week'] = daily_data['datetime'].dt.dayofweek\n",
    "daily_data['day_of_month'] = daily_data['datetime'].dt.day\n",
    "daily_data['day_of_quarter'] = (daily_data['datetime'].dt.dayofyear - 1) // 90 + 1\n",
    "daily_data['day_of_year'] = daily_data['datetime'].dt.dayofyear\n",
    "\n",
    "# Filter train and test data\n",
    "train_df = daily_data[(daily_data['datetime'] >= '2010-01-01') & (daily_data['datetime'] <= '2019-12-31')]\n",
    "test_df = daily_data[(daily_data['datetime'] >= '2020-01-01') & (daily_data['datetime'] <= '2020-12-31')]\n",
    "\n",
    "# Prepare the data for the LSTM model\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_scaled = scaler.fit_transform(train_df[['quantity', 'day_of_week', 'day_of_month', 'day_of_quarter', 'day_of_year']])\n",
    "test_scaled = scaler.transform(test_df[['quantity', 'day_of_week', 'day_of_month', 'day_of_quarter', 'day_of_year']])\n",
    "\n",
    "# Define function to create dataset\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        X.append(a)\n",
    "        Y.append(dataset[i + look_back, 0])  # Quantity is the target variable\n",
    "    X_array, Y_array = np.array(X), np.array(Y)\n",
    "    return X_array, Y_array\n",
    "\n",
    "look_back = 30  # Look back period\n",
    "trainX, trainY = create_dataset(train_scaled, look_back)\n",
    "testX, testY = create_dataset(test_scaled, look_back)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], trainX.shape[2]))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], testX.shape[2]))\n",
    "\n",
    "# Define the model\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=hp.Int('units1', min_value=50, max_value=200, step=50), return_sequences=True, input_shape=(look_back, trainX.shape[2])))\n",
    "    model.add(Dropout(rate=hp.Float('dropout1', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(units=hp.Int('units2', min_value=50, max_value=200, step=50), return_sequences=True))\n",
    "    model.add(Dropout(rate=hp.Float('dropout2', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "    model.add(LSTM(units=hp.Int('units3', min_value=50, max_value=200, step=50)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')))\n",
    "    return model\n",
    "\n",
    "# Hyperparameter tuning\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='pizza_demand_forecast'\n",
    ")\n",
    "\n",
    "tuner.search(trainX, trainY, epochs=50, validation_split=0.2, batch_size=32)\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Fit the best model\n",
    "best_model.fit(trainX, trainY, epochs=50, batch_size=32, verbose=2)\n",
    "\n",
    "# Make predictions\n",
    "trainPredict = best_model.predict(trainX)\n",
    "testPredict = best_model.predict(testX)\n",
    "\n",
    "# Inverse transform predictions and actual values\n",
    "trainPredict = scaler.inverse_transform(np.concatenate((trainPredict, np.zeros((trainPredict.shape[0], 4))), axis=1))[:,0]\n",
    "trainY = scaler.inverse_transform(np.concatenate((trainY.reshape(-1, 1), np.zeros((trainY.shape[0], 4))), axis=1))[:,0]\n",
    "testPredict = scaler.inverse_transform(np.concatenate((testPredict, np.zeros((testPredict.shape[0], 4))), axis=1))[:,0]\n",
    "testY = scaler.inverse_transform(np.concatenate((testY.reshape(-1, 1), np.zeros((testY.shape[0], 4))), axis=1))[:,0]\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "trainScore = np.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "testScore = np.sqrt(mean_squared_error(testY, testPredict))\n",
    "mae = mean_absolute_error(testY, testPredict)\n",
    "mse = mean_squared_error(testY, testPredict)\n",
    "rmse = np.sqrt(mse)  # Calculating RMSE from MSE\n",
    "mape = np.mean(np.abs((testY - testPredict) / testY)) * 100\n",
    "accuracy = 100 - mape\n",
    "\n",
    "# Print accuracy metrics\n",
    "print(f'Train RMSE: {trainScore}')\n",
    "print(f'Test RMSE: {testScore}')\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")  # Printing RMSE\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape}%\")\n",
    "print(f\"Accuracy: {accuracy}%\")\n",
    "\n",
    "# Extend test data to include up to January 2021\n",
    "test_df_extended = daily_data[(daily_data['datetime'] >= '2020-01-01') & (daily_data['datetime'] <= '2021-01-31')]\n",
    "extended_test_scaled = scaler.transform(test_df_extended[['quantity', 'day_of_week', 'day_of_month', 'day_of_quarter', 'day_of_year']])\n",
    "extended_testX, extended_testY = create_dataset(extended_test_scaled, look_back)\n",
    "extended_testX = np.reshape(extended_testX, (extended_testX.shape[0], extended_testX.shape[1], extended_testX.shape[2]))\n",
    "extended_testPredict = best_model.predict(extended_testX)\n",
    "extended_testPredict = scaler.inverse_transform(np.concatenate((extended_testPredict, np.zeros((extended_testPredict.shape[0], 4))), axis=1))[:,0]\n",
    "extended_testY = scaler.inverse_transform(np.concatenate((extended_testY.reshape(-1, 1), np.zeros((extended_testY.shape[0], 4))), axis=1))[:,0]\n",
    "\n",
    "# Error Analysis for the extended range\n",
    "error = extended_testY - extended_testPredict\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(test_df_extended['datetime'][look_back+1:], error, label='Prediction Error')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Prediction Error')\n",
    "plt.title('Prediction Error Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the results for the extended range\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(test_df_extended['datetime'][look_back+1:], extended_testY, label='Actual')\n",
    "plt.plot(test_df_extended['datetime'][look_back+1:], extended_testPredict, label='Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Quantity')\n",
    "plt.title('Actual vs Forecasted Pizza Demand')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame containing actual and predicted values along with dates for the extended range\n",
    "extended_results_df = pd.DataFrame({\n",
    "    'Date': test_df_extended['datetime'][look_back+1:],\n",
    "    'Actual_Quantity': extended_testY,\n",
    "    'Predicted_Quantity': extended_testPredict\n",
    "})\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "extended_results_df.to_excel('LSTM_season_qty_1_sam9_final.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
